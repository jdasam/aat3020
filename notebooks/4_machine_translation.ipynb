{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9187e26",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020-2023/blob/main/notebooks/4_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c87a7a",
      "metadata": {
        "id": "80c87a7a"
      },
      "source": [
        "# Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Y6OfzjCACzNM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6OfzjCACzNM",
        "outputId": "58e4af95-d671-499a-b3fe-c862b01d8595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "# install HuggingFace\n",
        "!pip install transformers tokenizers\n",
        "\n",
        "# If you are not using Colab, install below to read xlsx file\n",
        "# !pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "518b10da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "518b10da",
        "outputId": "4c3e7901-c21a-4423-df5f-5f5951246671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13CGLEULYccogSLByHXPAxSveLZTtnj8c\n",
            "From (redirected): https://drive.google.com/uc?id=13CGLEULYccogSLByHXPAxSveLZTtnj8c&confirm=t&uuid=85d68fb0-96a2-4844-980b-95f770c2cb90\n",
            "To: /home/teo/userdata/git_libraries/aat3020/notebooks/nia_korean_english_csv.zip\n",
            "100%|████████████████████████████████████████| 190M/190M [00:06<00:00, 28.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Download dataset (originally from NIA AI-Hub)\n",
        "'''\n",
        "\n",
        "# !gdown 1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g\n",
        "# !unzip -q nia-aihub-korean-english.zip\n",
        "\n",
        "# !gdown 1GMFWREWBVcD5vJdwNFadHmzVStclcyKf\n",
        "# !unzip -q nia-aihub-korean-english-txt.zip\n",
        "\n",
        "!gdown 13CGLEULYccogSLByHXPAxSveLZTtnj8c\n",
        "!unzip -q nia_korean_english_csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dWNSKjhdJ1jM",
      "metadata": {
        "id": "dWNSKjhdJ1jM"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"nia_korean_english.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7x-RgZcNk9I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "f7x-RgZcNk9I",
        "outputId": "7638e5b3-7aaf-4e18-cf7b-ccf3786470b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21156792-f76d-450e-8b12-4b42146b05e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...</td>\n",
              "      <td>Bible Coloring' is a coloring application that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>씨티은행에서 일하세요?</td>\n",
              "      <td>Do you work at a City bank?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.</td>\n",
              "      <td>PURITO's bestseller, which recorded 4th rough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.</td>\n",
              "      <td>In Chapter 11 Jesus called Lazarus from the to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.</td>\n",
              "      <td>I would feel grateful to know how many stocks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1602413</th>\n",
              "      <td>힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...</td>\n",
              "      <td>Across from the Hilton Hotel, the path to Hoeh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1602414</th>\n",
              "      <td>힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...</td>\n",
              "      <td>There are a lot of people who are having a har...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1602415</th>\n",
              "      <td>힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...</td>\n",
              "      <td>It was possible to make the Republic of Korea ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1602416</th>\n",
              "      <td>힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.</td>\n",
              "      <td>As for doing hard work, most of all, they shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1602417</th>\n",
              "      <td>힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...</td>\n",
              "      <td>I would like to thank all the leaders here for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1602418 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21156792-f76d-450e-8b12-4b42146b05e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21156792-f76d-450e-8b12-4b42146b05e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21156792-f76d-450e-8b12-4b42146b05e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                        원문  \\\n",
              "0        'Bible Coloring'은 성경의 아름다운 이야기를 체험 할 수 있는 컬러링 ...   \n",
              "1                                             씨티은행에서 일하세요?   \n",
              "2                    푸리토의 베스트셀러는 해외에서 입소문만으로 4차 완판을 기록하였다.   \n",
              "3         11장에서는 예수님이 이번엔 나사로를 무덤에서 불러내어 죽은 자 가운데서 살리셨습니다.   \n",
              "4           6.5, 7, 8 사이즈가 몇 개나 더 재입고 될지 제게 알려주시면 감사하겠습니다.   \n",
              "...                                                    ...   \n",
              "1602413  힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...   \n",
              "1602414  힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...   \n",
              "1602415  힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...   \n",
              "1602416  힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.   \n",
              "1602417  힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...   \n",
              "\n",
              "                                                       번역문  \n",
              "0        Bible Coloring' is a coloring application that...  \n",
              "1                              Do you work at a City bank?  \n",
              "2        PURITO's bestseller, which recorded 4th rough ...  \n",
              "3        In Chapter 11 Jesus called Lazarus from the to...  \n",
              "4        I would feel grateful to know how many stocks ...  \n",
              "...                                                    ...  \n",
              "1602413  Across from the Hilton Hotel, the path to Hoeh...  \n",
              "1602414  There are a lot of people who are having a har...  \n",
              "1602415  It was possible to make the Republic of Korea ...  \n",
              "1602416  As for doing hard work, most of all, they shou...  \n",
              "1602417  I would like to thank all the leaders here for...  \n",
              "\n",
              "[1602418 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8b8786",
      "metadata": {
        "id": "ff8b8786"
      },
      "outputs": [],
      "source": [
        "df['원문'][10000:10050], df['번역문'][10000:10050]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df6e584",
      "metadata": {
        "id": "3df6e584"
      },
      "source": [
        "## Huggingface Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c6f1769",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c6f1769",
        "outputId": "f1f0dfad-d93b-482d-8c92-d46bc4177580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['hugging_eng_32000/vocab.txt']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
        "\n",
        "num_files = len(data_list)\n",
        "\n",
        "corpus_file   =  [str(path.parent / (path.stem + '_kor.txt')) for path in data_list[:num_files]]\n",
        "# output_dir   = Path('hugging_kor_%d'%(vocab_size))\n",
        "en_corpus_file   =  [str(path.parent / (path.stem + '_eng.txt')) for path in data_list[:num_files]]\n",
        "# output_dir   = Path('hugging_eng_%d'%(vocab_size))\n",
        "\n",
        "vocab_size    = 32000  # Number of maximum size of the vocabulary\n",
        "limit_alphabet= 6000   \n",
        "output_dir    = Path('hugging_kor_%d'%(vocab_size))\n",
        "en_output_dir = Path('hugging_eng_%d'%(vocab_size))\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "en_output_dir.mkdir(exist_ok=True)\n",
        "min_frequency = 5 \n",
        "\n",
        "tokenizer.train(files=corpus_file,\n",
        "               vocab_size=vocab_size,\n",
        "               min_frequency=min_frequency,\n",
        "               limit_alphabet=limit_alphabet, \n",
        "               show_progress=True)\n",
        "\n",
        "tokenizer.save_model(str(output_dir))\n",
        "\n",
        "en_tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
        "en_tokenizer.train(files=en_corpus_file,\n",
        "                vocab_size=vocab_size,\n",
        "                min_frequency=min_frequency,\n",
        "                limit_alphabet=limit_alphabet,\n",
        "                show_progress=True)\n",
        "en_tokenizer.save_model(str(en_output_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "410eb97a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "410eb97a",
        "outputId": "63edc607-3035-4141-aae5-a6da58127b1e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "나는 친구에게 그 철학자의 책을 선물해 주겠다고 말했습니다.\n",
            "[CLS] 나는 친구에게 그 철학자의 책을 선물해 주겠다고 말했습니다. [SEP]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer_src = BertTokenizerFast.from_pretrained('hugging_kor_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n",
        "tokenizer_tgt = BertTokenizerFast.from_pretrained('hugging_eng_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n",
        "\n",
        "tokenized_data = tokenizer_src(df['원문'].iloc[10])\n",
        "print(df['원문'].iloc[10])\n",
        "print(tokenizer_src.decode(tokenized_data['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q9GJ7cifk5tg",
      "metadata": {
        "id": "q9GJ7cifk5tg"
      },
      "outputs": [],
      "source": [
        "tokenized_data['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340f55c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "340f55c0",
        "outputId": "15b66d7d-e619-4672-dc5c-038218608974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 6481, 25257, 8055, 4330, 2537, 10839, 3]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_ids = tokenizer_src(\"나는 서강대학교에 다닙니다\")['input_ids']\n",
        "tokenized_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3ea831",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5b3ea831",
        "outputId": "04621101-cf34-4b8d-e1b4-a747c445e8c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] 나는 서강대학교에 다닙니다 [SEP]'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_src.decode(tokenized_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26964dcb",
      "metadata": {
        "id": "26964dcb"
      },
      "source": [
        "## Divide Train / Validate/ Test Set\n",
        "- using `np.random.choice`\n",
        "    - To always get the same random shuffling result, you have to use `np.random.seed()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B2zJgvXPlh95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "B2zJgvXPlh95",
        "outputId": "33f24480-2a88-418e-d95d-b01f5b6050d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d659cf52-06c5-4062-a100-2c32cbe09de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>지자체</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>261811</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 말산업 육성을 위해 총예산 245,193천원으로 2013년 경기도 용인시...</td>\n",
              "      <td>\"The Gyeonggi provincial government announced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>409852</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 경기FTA활용지원센터와 코트라가 주관한 이번 시장개척단은 지난 ...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>352671</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 경기도비정규직지원센터가 주관한 이번 교육은 공공 부문이 직·간접...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>308191</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 사단법인 한국장애인복지시설협회 경기도협회(대표자:정권)에서 주관...</td>\n",
              "      <td>\"Organized by Gyeonggi provincial government a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>185424</td>\n",
              "      <td>경기도</td>\n",
              "      <td>\"경기도가 주최하고 인구보건복지협회 경기지회, 아이낳기좋은세상 경기운동본부가 주관하...</td>\n",
              "      <td>\"Hosted by Gyeonggi provincial government, org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100082</th>\n",
              "      <td>73961</td>\n",
              "      <td>서울시 중구</td>\n",
              "      <td>힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...</td>\n",
              "      <td>Across from the Hilton Hotel, the path to Hoeh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100083</th>\n",
              "      <td>462950</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...</td>\n",
              "      <td>There are a lot of people who are having a har...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100084</th>\n",
              "      <td>333006</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...</td>\n",
              "      <td>It was possible to make the Republic of Korea ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100085</th>\n",
              "      <td>454399</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.</td>\n",
              "      <td>As for doing hard work, most of all, they shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100086</th>\n",
              "      <td>507679</td>\n",
              "      <td>경기도</td>\n",
              "      <td>힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...</td>\n",
              "      <td>I would like to thank all the leaders here for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100087 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d659cf52-06c5-4062-a100-2c32cbe09de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d659cf52-06c5-4062-a100-2c32cbe09de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d659cf52-06c5-4062-a100-2c32cbe09de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ID     지자체                                                 원문  \\\n",
              "0       261811     경기도  \"경기도가 말산업 육성을 위해 총예산 245,193천원으로 2013년 경기도 용인시...   \n",
              "1       409852     경기도  \"경기도가 주최하고 경기FTA활용지원센터와 코트라가 주관한 이번 시장개척단은 지난 ...   \n",
              "2       352671     경기도  \"경기도가 주최하고 경기도비정규직지원센터가 주관한 이번 교육은 공공 부문이 직·간접...   \n",
              "3       308191     경기도  \"경기도가 주최하고 사단법인 한국장애인복지시설협회 경기도협회(대표자:정권)에서 주관...   \n",
              "4       185424     경기도  \"경기도가 주최하고 인구보건복지협회 경기지회, 아이낳기좋은세상 경기운동본부가 주관하...   \n",
              "...        ...     ...                                                ...   \n",
              "100082   73961  서울시 중구  힐튼호텔 건너편에서 회현동주민센터로 내려가는 길에는 칙칙한 회색의 석축옹벽이 이어져...   \n",
              "100083  462950     경기도  힘든 분들이 많이 계시지만 조금이나마 어렵지 않도록 도움이 될 수 있도록 저희가 최...   \n",
              "100084  333006     경기도  힘든 역사 속에서 대한민국을 불과 50여년 만에 빛나는 나라로 만들고 업적을 만들 ...   \n",
              "100085  454399     경기도  힘든 일을 하는 데는 무엇보다 정부가 큰 관심을 갖고 있다는 자부심을 갖도록 해야 한다.   \n",
              "100086  507679     경기도  힘을 합쳐 세계 일류통일강국으로 대한민국을 우뚝 세우는 역할을 이 자리의 모든 지도...   \n",
              "\n",
              "                                                      번역문  \n",
              "0       \"The Gyeonggi provincial government announced ...  \n",
              "1       \"Organized by Gyeonggi provincial government a...  \n",
              "2       \"Organized by Gyeonggi provincial government a...  \n",
              "3       \"Organized by Gyeonggi provincial government a...  \n",
              "4       \"Hosted by Gyeonggi provincial government, org...  \n",
              "...                                                   ...  \n",
              "100082  Across from the Hilton Hotel, the path to Hoeh...  \n",
              "100083  There are a lot of people who are having a har...  \n",
              "100084  It was possible to make the Republic of Korea ...  \n",
              "100085  As for doing hard work, most of all, they shou...  \n",
              "100086  I would like to thank all the leaders here for...  \n",
              "\n",
              "[100087 rows x 4 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba4a138a",
      "metadata": {
        "id": "ba4a138a"
      },
      "source": [
        "## Define Dataset\n",
        "- Each datasample has to return source sentence and target sentence\n",
        "- You need a Tokenizer to get the tokenized result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kMaE7cK2EurA",
      "metadata": {
        "id": "kMaE7cK2EurA"
      },
      "source": [
        "## Split Dataset\n",
        "- using ``torch.utils.data.random_split(dataset)``"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a9f0ec",
      "metadata": {
        "id": "f4a9f0ec"
      },
      "source": [
        "## Define Collate function\n",
        "- After implementing Dataset, we have to declare DataLoader that groups several training samples as a single batch\n",
        "- However, we cannot batchify the melodies in straightforward way, because the length of each melody is different\n",
        "- In this problem, you will learn about how to handle sequences of different length as a batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22db0716",
      "metadata": {
        "id": "22db0716"
      },
      "source": [
        "#### Pad Sequence and Pack Sequence\n",
        "In PyTorch, there are two ways to batchify a group of sequence with different length.\n",
        "- `torch.nn.utils.rnn.pad_sequence`\n",
        "    - This function takes list of tensors with different length and return padded sequence\n",
        "    - Padding is adding some constant number as a PAD token to match the length of short sequence to the maximum length\n",
        "        - e.g. If there are sequence of length (3,7,4), we can add 4 zeros to sequence with length 3, 3 zeros to sequence with length 4 to make them length 7\n",
        "    - In default, we use 0 for padding (zero padding)\n",
        "    - The result \n",
        "- `torch.nn.utils.rnn.pack_sequence`\n",
        "    - pad_sequence "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c8cce88",
      "metadata": {
        "id": "1c8cce88"
      },
      "source": [
        "Cells below show the example of `pad_sequence`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb5e0dd",
      "metadata": {
        "id": "4fb5e0dd"
      },
      "source": [
        "1) However, the problem is that you can't figure out whether the 0 at the end of each sequence is a padded one, or was included in the original sequence\n",
        "- e.g. `[2, 3, 4, 3, 0]` becomes `[ 2,  3,  4,  5,  0,  0,  0]`. Now we don't know how many zeros were added for padding\n",
        "\n",
        "2) Also, if you run RNN for this padded sequence, RNN will calculate for the padded part also.\n",
        "- RNN doesn't know whether it is padded data, or existing data\n",
        "- This makes computation slower\n",
        "\n",
        "3) If you want to use bi-directional, which also reads the sequence from backward, paddings can make the result different.\n",
        "\n",
        "To solve this issue, we use PackedSequence, by using `pack_sequence`/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd50747",
      "metadata": {
        "id": "4cd50747"
      },
      "source": [
        "`PackedSequence` has `data` and `batch_sizes`\n",
        "- `data` contains the flattened value of given batch\n",
        "    - To optimize the computation, the sequences have to be sorted by descending of length\n",
        "- `batch_sizes` represents how many valid batch sample exists for each time step\n",
        "    - `[3, 3, 3, 2, 2, 1, 1]` means that there are 3 sequences for first three time steps, and then 2 sequences for next two steps, and then only 1 sequence for next two steps.\n",
        "- `sorted_indices` shows how the sorted sequences can be converted to original order.\n",
        "    - `[1,2,0]` means that \n",
        "        - the 0th sequence in the sorted sequences (the longest one) was indexed as 1 in the original input batch\n",
        "        - the 1st sequence in the sorted sequences (`middle`) was indexed as 2 in the original input batch\n",
        "        - the 2nd sequence in the sorted sequences (`short`) was index as 0 in the original input batch\n",
        "- `unsorted_indices` shows how the original sequences are sorted.\n",
        "    - `[2,0,1]` means that\n",
        "        - the 0th sequence in the original input was sorted as 2nd in the sorted sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2e3e44",
      "metadata": {
        "id": "8f2e3e44"
      },
      "source": [
        "- RNN or its family of PyTorch can automatically handle `PackedSequence`\n",
        "- However, other layers like `nn.Embedding` or `nn.Linear` cannot take `PackedSequence` as its input\n",
        "- There are two ways to feed `PackedSequence` to these layers\n",
        "    - First, convert PackedSequence to ordinary torch.Tensor by `torch.nn.utils.rnn.pad_packed_sequence`\n",
        "        - This will convert PackedSequence to a tensor of sequneces with same length but different padding\n",
        "    - The other way is to feed only PackedSequence.data, and then declaring new PackedSequence with the output as `data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08620c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "b08620c8",
        "outputId": "cfd89d73-ff95-4355-aefe-1983a840d1fe"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7c62b9259c97>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_linear_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_linear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not PackedSequence"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This will make error, because other layers cannot handle PackedSequence\n",
        "'''\n",
        "test_linear_layer = nn.Linear(in_features=1, out_features=2)\n",
        "test_linear_layer(packed_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9efa09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac9efa09",
        "outputId": "6e266ee3-8dca-4314-fe10-91ee15a0def3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The padded sequence generated from packed sequence (squeezed for printing): \n",
            " tensor([[ 3., 27., 15.],\n",
            "        [ 2., 26., 14.],\n",
            "        [ 1., 25., 13.],\n",
            "        [ 0., 24., 12.],\n",
            "        [ 0., 23., 11.],\n",
            "        [ 0., 22., 10.],\n",
            "        [ 0., 21.,  0.],\n",
            "        [ 0., 20.,  0.]])\n",
            "\"pad_packed_sequence\" also returns \"batch_lengths\", to clarify the original length before the padding: \n",
            " tensor([4, 8, 6])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One way to to this is using torch.nn.utils.rnn.pad_packed_sequence to convert PackedSequence to ordinary padded tensor\n",
        "'''\n",
        "\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "padded_sequence, batch_lengths = pad_packed_sequence(packed_sequence)\n",
        "print(f'The padded sequence generated from packed sequence (squeezed for printing): \\n {padded_sequence.squeeze()}')\n",
        "print(f'\"pad_packed_sequence\" also returns \"batch_lengths\", to clarify the original length before the padding: \\n {batch_lengths}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e302fe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e302fe4",
        "outputId": "af6d0e8e-3e46-426a-f23f-ce6e534dff67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output of feeding padded_sequence to a linear layer: tensor([[[ 3.3898,  1.8743],\n",
            "         [24.5948, 12.2365],\n",
            "         [13.9923,  7.0554]],\n",
            "\n",
            "        [[ 2.5063,  1.4426],\n",
            "         [23.7113, 11.8048],\n",
            "         [13.1088,  6.6237]],\n",
            "\n",
            "        [[ 1.6227,  1.0108],\n",
            "         [22.8277, 11.3730],\n",
            "         [12.2252,  6.1919]],\n",
            "\n",
            "        [[ 0.7392,  0.5791],\n",
            "         [21.9442, 10.9413],\n",
            "         [11.3417,  5.7602]],\n",
            "\n",
            "        [[ 0.7392,  0.5791],\n",
            "         [21.0606, 10.5095],\n",
            "         [10.4581,  5.3284]],\n",
            "\n",
            "        [[ 0.7392,  0.5791],\n",
            "         [20.1771, 10.0777],\n",
            "         [ 9.5746,  4.8966]],\n",
            "\n",
            "        [[ 0.7392,  0.5791],\n",
            "         [19.2936,  9.6460],\n",
            "         [ 0.7392,  0.5791]],\n",
            "\n",
            "        [[ 0.7392,  0.5791],\n",
            "         [18.4100,  9.2142],\n",
            "         [ 0.7392,  0.5791]]], grad_fn=<ViewBackward0>)\n",
            "Caution that it returns non-zero values for timestep with zero padding, because linear layer has a bias\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Now you can feed padded sequence to linear layer.\n",
        "'''\n",
        "\n",
        "linear_output = test_linear_layer(padded_sequence)\n",
        "print(f\"Output of feeding padded_sequence to a linear layer: {linear_output}\")\n",
        "print(\"Caution that it returns non-zero values for timestep with zero padding, because linear layer has a bias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c0e150",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c0e150",
        "outputId": "8cb4f6cd-0d17-4eda-f300-85bc96e46004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[24.5948, 12.2365],\n",
              "        [13.9923,  7.0554],\n",
              "        [ 3.3898,  1.8743],\n",
              "        [23.7113, 11.8048],\n",
              "        [13.1088,  6.6237],\n",
              "        [ 2.5063,  1.4426],\n",
              "        [22.8277, 11.3730],\n",
              "        [12.2252,  6.1919],\n",
              "        [ 1.6227,  1.0108],\n",
              "        [21.9442, 10.9413],\n",
              "        [11.3417,  5.7602],\n",
              "        [ 0.7392,  0.5791],\n",
              "        [21.0606, 10.5095],\n",
              "        [10.4581,  5.3284],\n",
              "        [20.1771, 10.0777],\n",
              "        [ 9.5746,  4.8966],\n",
              "        [19.2936,  9.6460],\n",
              "        [18.4100,  9.2142]], grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([1, 2, 0]), unsorted_indices=tensor([2, 0, 1]))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "You can make the output as a PackedSequence, by using torch.nn.utils.rnn.pack_padded_sequence\n",
        "'''\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "re_packed_sequence = pack_padded_sequence(linear_output, batch_lengths, enforce_sorted=False)\n",
        "re_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22117c41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22117c41",
        "outputId": "9f1bbb93-b344-46c3-dc04-e41d059ad0b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[24.5948, 12.2365],\n",
              "        [13.9923,  7.0554],\n",
              "        [ 3.3898,  1.8743],\n",
              "        [23.7113, 11.8048],\n",
              "        [13.1088,  6.6237],\n",
              "        [ 2.5063,  1.4426],\n",
              "        [22.8277, 11.3730],\n",
              "        [12.2252,  6.1919],\n",
              "        [ 1.6227,  1.0108],\n",
              "        [21.9442, 10.9413],\n",
              "        [11.3417,  5.7602],\n",
              "        [ 0.7392,  0.5791],\n",
              "        [21.0606, 10.5095],\n",
              "        [10.4581,  5.3284],\n",
              "        [20.1771, 10.0777],\n",
              "        [ 9.5746,  4.8966],\n",
              "        [19.2936,  9.6460],\n",
              "        [18.4100,  9.2142]], grad_fn=<AddmmBackward0>), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([1, 2, 0]), unsorted_indices=tensor([2, 0, 1]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Another way to do it is using PackedSequence.data\n",
        "'''\n",
        "\n",
        "linear_out_pack = test_linear_layer(packed_sequence.data)\n",
        "packed_sequence_after_linear = PackedSequence(linear_out_pack, packed_sequence.batch_sizes, packed_sequence.sorted_indices, packed_sequence.unsorted_indices)\n",
        "packed_sequence_after_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "81dd119c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "81dd119c",
        "outputId": "4040a73b-c3f9-4f86-d8a7-6119883800e5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3d6fe6143c0a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_collate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pack_sequence, PackedSequence\n",
        "\n",
        "def pack_collate(raw_batch):\n",
        "  source, target, shifted_target = zip(*raw_batch)\n",
        "  return pack_sequence(source, enforce_sorted=False), pack_sequence(target, enforce_sorted=False), pack_sequence(shifted_target, enforce_sorted=False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, collate_fn=pack_collate)\n",
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LiWbuM8SPVop",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiWbuM8SPVop",
        "outputId": "21a36a56-2ddd-4d40-b603-223caef71a3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([21, 17, 14,  5, 27,  8, 24, 28,  3,  9, 13, 29,  4, 16,  0, 19, 22,  2,\n",
              "         10, 20, 25, 23, 31, 15,  7, 18, 11, 12, 26, 30,  1,  6]),\n",
              " tensor([21,  5, 24, 13,  3, 17,  8,  4, 14, 16, 28, 27, 29,  0, 19,  9,  2, 22,\n",
              "         25, 20, 18, 23, 31, 11, 10,  7, 30, 15,  1, 12, 26,  6]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src, tgt, shifted_tgt = batch\n",
        "src.sorted_indices, tgt.sorted_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357c61f4",
      "metadata": {
        "id": "357c61f4"
      },
      "source": [
        "## Define Model\n",
        "![image](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0af0ca29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "0af0ca29",
        "outputId": "e3776f5b-738b-45a9-ad8f-eceeccaf103f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9883e73544ac>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifted_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "class Seq2seq(nn.Module):\n",
        "  def __init__(self, enc_vocab, dec_vocab, hidden_size, num_layers=2):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(enc_vocab, hidden_size, num_layers=num_layers)\n",
        "    self.decoder = Decoder(dec_vocab, hidden_size, num_layers=num_layers)\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    enc_out = self.encoder(src)\n",
        "    # if isinstance(src, PackedSequence) and isinstance(tgt, PackedSequence):\n",
        "    #   enc_out = enc_out[:, src.unsorted_indices][:, tgt.sorted_indices ]\n",
        "    dec_out = self.decoder(tgt, enc_out)\n",
        "    return dec_out \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_vocab, hidden_size, num_layers=2):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_vocab, hidden_size)\n",
        "    self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=num_layers)\n",
        "    # batch_first True: it takes (Num_samples_in_batch, num_timesteps, num_dim)\n",
        "    # batch_first False: it takes (num_timesteps, Num_samples_in_batch, num_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if isinstance(x, PackedSequence):\n",
        "      emb = PackedSequence(self.emb(x.data), batch_sizes=x.batch_sizes, sorted_indices=x.sorted_indices, unsorted_indices=x.unsorted_indices)\n",
        "    else:\n",
        "      emb = self.emb(x)\n",
        "    out, last_hidden = self.rnn(emb)\n",
        "    # Even though input is PackedSequence, last_hidden is always tensor\n",
        "    # in \"unsorted_order\"\n",
        "    # last_hidden[:, 0] means 0th sample in the raw (unsorted) batch\n",
        "    return last_hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_vocab, hidden_size, num_layers=2):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(num_vocab, hidden_size)\n",
        "    self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=num_layers)\n",
        "    self.proj = nn.Linear(hidden_size, num_vocab)\n",
        "\n",
        "\n",
        "  def forward(self, x, enc_output):\n",
        "    if isinstance(x, PackedSequence):\n",
        "      emb = PackedSequence(self.emb(x.data), batch_sizes=x.batch_sizes, sorted_indices=x.sorted_indices, unsorted_indices=x.unsorted_indices)\n",
        "      out, last_hidden = self.rnn(emb, enc_output)\n",
        "      # You have to feed last_hidden to rnn following unsorted_indices \n",
        "      # when you feed PackedSequence input to RNN.\n",
        "      logit = PackedSequence(self.proj(out.data), batch_sizes=out.batch_sizes, sorted_indices=out.sorted_indices, unsorted_indices=out.unsorted_indices)\n",
        "    else:\n",
        "      emb = self.emb(x)\n",
        "      out, last_hidden = self.rnn(emb, enc_output)\n",
        "      logit = self.proj(out)\n",
        "    return logit\n",
        "    \n",
        "hidden_size = 64\n",
        "model = Seq2seq(tokenizer_src.vocab_size, tokenizer_tgt.vocab_size, hidden_size)\n",
        "encoder = Encoder(tokenizer_src.vocab_size, hidden_size)\n",
        "decoder = Decoder(tokenizer_tgt.vocab_size, hidden_size)\n",
        "\n",
        "src, tgt, shifted_tgt = batch\n",
        "\n",
        "enc_out = encoder(src)\n",
        "dec_out = decoder(tgt, enc_out)\n",
        "\n",
        "logit = model(src, tgt)\n",
        "# logit.shape, logit.softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ld6OZjJ_Qdar",
      "metadata": {
        "id": "Ld6OZjJ_Qdar"
      },
      "outputs": [],
      "source": [
        "unsorted_enc_out = enc_out[:, src.unsorted_indices]\n",
        "target_sorted_enc_out = unsorted_enc_out[:, tgt.sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lj7zFQPqOkNk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj7zFQPqOkNk",
        "outputId": "8e09d4dd-2978-4ad7-c4ac-6eec740df0cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[-0.1037,  0.1473,  0.0048,  ..., -0.0047, -0.1110, -0.0725],\n",
              "        [-0.1180,  0.1796,  0.0051,  ..., -0.0034, -0.1301, -0.0628],\n",
              "        [-0.1426,  0.1752,  0.0121,  ..., -0.0245, -0.0783, -0.0516],\n",
              "        ...,\n",
              "        [ 0.0704,  0.0287,  0.0330,  ...,  0.0372, -0.1235,  0.0724],\n",
              "        [ 0.0297,  0.0548, -0.0590,  ..., -0.0222, -0.1012,  0.0353],\n",
              "        [ 0.0028,  0.0724, -0.0668,  ...,  0.0017, -0.0646,  0.0580]],\n",
              "       grad_fn=<AddmmBackward0>), batch_sizes=tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=tensor([5, 3, 4, 0, 2, 7, 1, 6]), unsorted_indices=tensor([3, 6, 4, 1, 2, 0, 7, 5]))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WMGUwt10Whf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMGUwt10Whf5",
        "outputId": "53bf8946-490b-41cd-ca60-8eaa32b28fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 30679]),\n",
              " torch.Size([1, 10]),\n",
              " tensor([[  76,   10,  746,  810,  906,  335,  412, 2590,   17,    3]]))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logit.shape, shifted_tgt.shape, shifted_tgt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ffb21b",
      "metadata": {
        "id": "13ffb21b"
      },
      "source": [
        "## Define Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1eeaf7",
      "metadata": {
        "id": "4a1eeaf7"
      },
      "source": [
        "- You can download pre-trained weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d79bbee3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d79bbee3",
        "outputId": "25e87023-fac9-4d32-f5a7-245a6f691ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15jL2TaRk6Q47uuPWDruUge6O_gCPv5mp\n",
            "To: /content/kor_eng_translator_model_vanilla_best.pt\n",
            "100% 704M/704M [00:09<00:00, 78.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown 127OoPv8-lF5TWeNCq9PNa8igyGQnR-Pe\n",
        "!gdown 15jL2TaRk6Q47uuPWDruUge6O_gCPv5mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "luIbc92ui73D",
      "metadata": {
        "id": "luIbc92ui73D"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "YvQCKX1xR5hl",
      "metadata": {
        "id": "YvQCKX1xR5hl"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load(\"kor_eng_translator_model_vanilla_best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1916a074",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1916a074",
        "outputId": "f8eafc4a-2b22-42a8-da3b-0703a80f0fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_size = 512\n",
        "model = Seq2seq(tokenizer_src.vocab_size, tokenizer_tgt.vocab_size, hidden_size, num_layers=3)\n",
        "\n",
        "model.load_state_dict(state_dict['model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "i9IHZNrcSmnz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i9IHZNrcSmnz",
        "outputId": "f8cda94b-60fa-431e-9263-16212b7dcf72"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this model is translated into korean in english.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Translator:\n",
        "  def __init__(self, model, src_tokenizer, tgt_tokenizer):\n",
        "    self.model = model\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    self.model.eval()\n",
        "    self.model.cpu()\n",
        "\n",
        "    self.start_token_idx = 2\n",
        "    self.end_token_idx = 3\n",
        "\n",
        "  def __call__(self, astr):\n",
        "    encoded_tokens = self.src_tokenizer.encode(astr)\n",
        "    encoded_tokens = torch.tensor(encoded_tokens, dtype=torch.long)\n",
        "\n",
        "    # run models encoder to get encoder out\n",
        "    enc_out = model.encoder(encoded_tokens)\n",
        "    # run decoder one-by-one\n",
        "    current_token = torch.tensor([self.start_token_idx]) # start of the sentence token\n",
        "    prev_hidden = enc_out\n",
        "    outputs = []\n",
        "    for i in range(50):\n",
        "      emb = self.model.decoder.emb(current_token)\n",
        "      dec_out, cur_hidden = self.model.decoder.rnn(emb, prev_hidden)\n",
        "      logit = self.model.decoder.proj(dec_out)\n",
        "      selected_token_idx = torch.argmax(logit, dim=-1)\n",
        "\n",
        "      # check the generated token is <end> token\n",
        "      if selected_token_idx.squeeze().item() == self.end_token_idx:\n",
        "        break\n",
        "\n",
        "      # update information\n",
        "      current_token = selected_token_idx\n",
        "      prev_hidden = cur_hidden\n",
        "      outputs.append(current_token.item())\n",
        "    \n",
        "    return self.tgt_tokenizer.decode(outputs)\n",
        "  \n",
        "translator = Translator(model, tokenizer_src, tokenizer_tgt)\n",
        "translator('이 모델은 한국어 문장을 영어로 번역합니다')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qU0XjE2YTBnb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU0XjE2YTBnb",
        "outputId": "153e695c-62be-4f33-baa6-de9c1e46f8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 6481, 10499, 9414, 6507, 3]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_src.encode('나는 수업을 듣고 있습니다')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0eb7936f98394185a72a8eb807798fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f296f0327c43378b8e2cca2ac83ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29011e908581492ebcb84b39c77fcc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce4571ca8c3486db82cf5111b49b979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eb7936f98394185a72a8eb807798fe4",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4102090d5d4f079c0a23a218648049",
            "value": "  0%"
          }
        },
        "3e01a4e4ef104f42a255d072e865d0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c202c1da2c3549b1b759e9bc8609ffcd",
            "placeholder": "​",
            "style": "IPY_MODEL_11f296f0327c43378b8e2cca2ac83ce8",
            "value": " 14326/160000 [02:02&lt;19:28, 124.68it/s]"
          }
        },
        "496ec14697464ddf922fb72560efeabc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0a96248ad549d6989d9cc4a58bc10f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4102090d5d4f079c0a23a218648049": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f476d7d8e84e8a81539a9a3549c1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d0a96248ad549d6989d9cc4a58bc10f",
            "placeholder": "​",
            "style": "IPY_MODEL_ccdb06e71d874d1f8210776f1f74ea28",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "5daec47eff3040788002690b9d9ff559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa45e83d15cb442fb7890f9ccedac956",
              "IPY_MODEL_a1f02abecc824b7b9f94ba2546ea7041",
              "IPY_MODEL_3e01a4e4ef104f42a255d072e865d0ec"
            ],
            "layout": "IPY_MODEL_496ec14697464ddf922fb72560efeabc"
          }
        },
        "601a23ba484145af8eec1946779a53d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0c64845c244720b529a238fb7f03fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ce4571ca8c3486db82cf5111b49b979",
              "IPY_MODEL_d01cea5d86be431fa519656159469c88",
              "IPY_MODEL_50f476d7d8e84e8a81539a9a3549c1d4"
            ],
            "layout": "IPY_MODEL_601a23ba484145af8eec1946779a53d8"
          }
        },
        "87be8f11d7304eea98f48b2f49448a24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e2fea28b8e4386903bd5dbd39c9a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f02abecc824b7b9f94ba2546ea7041": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e2fea28b8e4386903bd5dbd39c9a2f",
            "max": 160000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f63757eee857429c83bf8bba81a36ff6",
            "value": 14326
          }
        },
        "bb4843917abc42d68b3df2fbb3d90519": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c202c1da2c3549b1b759e9bc8609ffcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccdb06e71d874d1f8210776f1f74ea28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d01cea5d86be431fa519656159469c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87be8f11d7304eea98f48b2f49448a24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e718ea3aae714c89aaee1f1f79374cab",
            "value": 0
          }
        },
        "e718ea3aae714c89aaee1f1f79374cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f63757eee857429c83bf8bba81a36ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa45e83d15cb442fb7890f9ccedac956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb4843917abc42d68b3df2fbb3d90519",
            "placeholder": "​",
            "style": "IPY_MODEL_29011e908581492ebcb84b39c77fcc06",
            "value": "  9%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
