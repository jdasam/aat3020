{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020/blob/main/notebooks/2_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a2da87"
      },
      "source": [
        "# Named Entity Recognition\n",
        "- For a given word and its context window, estimate whether the given word is location or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11619f5d"
      },
      "source": [
        "# 1. Download dataset\n",
        "- CoNLL2003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a4faa3",
        "outputId": "d9f5a95d-eff1-4cf0-88d7-014e58a57f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-02 06:43:02--  https://data.deepai.org/conll2003.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 143.244.50.87, 2400:52e0:1a01::993:1\n",
            "Connecting to data.deepai.org (data.deepai.org)|143.244.50.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 982975 (960K) [application/zip]\n",
            "Saving to: ‘conll2003.zip’\n",
            "\n",
            "conll2003.zip       100%[===================>] 959.94K  5.17MB/s    in 0.2s    \n",
            "\n",
            "2024-04-02 06:43:03 (5.17 MB/s) - ‘conll2003.zip’ saved [982975/982975]\n",
            "\n",
            "Archive:  conll2003.zip\n",
            "  inflating: metadata                \n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: valid.txt               \n"
          ]
        }
      ],
      "source": [
        "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
        "!unzip conll2003.zip # Unzip dataset zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7643dde5"
      },
      "source": [
        "## 2. Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31874b2",
        "outputId": "75902a6b-cee7-416a-9bd4-f9c7dc94a5dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-DOCSTART- -X- -X- O',\n",
              " '',\n",
              " 'EU NNP B-NP B-ORG',\n",
              " 'rejects VBZ B-VP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'call NN I-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'boycott VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Peter NNP B-NP B-PER',\n",
              " 'Blackburn NNP I-NP I-PER',\n",
              " '',\n",
              " 'BRUSSELS NNP B-NP B-LOC',\n",
              " '1996-08-22 CD I-NP O',\n",
              " '',\n",
              " 'The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Thursday NNP B-NP O',\n",
              " 'it PRP B-NP O',\n",
              " 'disagreed VBD B-VP O',\n",
              " 'with IN B-PP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'advice NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'consumers NNS B-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'shun VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " 'until IN B-SBAR O',\n",
              " 'scientists NNS B-NP O',\n",
              " 'determine VBP B-VP O',\n",
              " 'whether IN B-SBAR O',\n",
              " 'mad JJ B-NP O',\n",
              " 'cow NN I-NP O',\n",
              " 'disease NN I-NP O',\n",
              " 'can MD B-VP O',\n",
              " 'be VB I-VP O',\n",
              " 'transmitted VBN I-VP O',\n",
              " 'to TO B-PP O',\n",
              " 'sheep NN B-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Germany NNP B-NP B-LOC',\n",
              " \"'s POS B-NP O\",\n",
              " 'representative NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'the DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Union NNP I-NP I-ORG',\n",
              " \"'s POS B-NP O\",\n",
              " 'veterinary JJ I-NP O',\n",
              " 'committee NN I-NP O',\n",
              " 'Werner NNP I-NP B-PER',\n",
              " 'Zwingmann NNP I-NP I-PER',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Wednesday NNP B-NP O',\n",
              " 'consumers NNS I-NP O',\n",
              " 'should MD B-VP O',\n",
              " 'buy VB I-VP O',\n",
              " 'sheepmeat NN B-NP O',\n",
              " 'from IN B-PP O',\n",
              " 'countries NNS B-NP O']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "with open(\"train.txt\") as f:\n",
        "  string = ''.join(f.readlines())\n",
        "dataset = string.split('\\n')\n",
        "\n",
        "dataset[:70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49e7f34b",
        "outputId": "ade772fe-17e8-4ed1-a3fd-642a3084f1eb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-DOCSTART- -X- -X- O'],\n",
              " ['EU NNP B-NP B-ORG',\n",
              "  'rejects VBZ B-VP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'call NN I-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'boycott VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  '. . O O'],\n",
              " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
              " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
              " ['The DT B-NP O',\n",
              "  'European NNP I-NP B-ORG',\n",
              "  'Commission NNP I-NP I-ORG',\n",
              "  'said VBD B-VP O',\n",
              "  'on IN B-PP O',\n",
              "  'Thursday NNP B-NP O',\n",
              "  'it PRP B-NP O',\n",
              "  'disagreed VBD B-VP O',\n",
              "  'with IN B-PP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'advice NN I-NP O',\n",
              "  'to TO B-PP O',\n",
              "  'consumers NNS B-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'shun VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  'until IN B-SBAR O',\n",
              "  'scientists NNS B-NP O',\n",
              "  'determine VBP B-VP O',\n",
              "  'whether IN B-SBAR O',\n",
              "  'mad JJ B-NP O',\n",
              "  'cow NN I-NP O',\n",
              "  'disease NN I-NP O',\n",
              "  'can MD B-VP O',\n",
              "  'be VB I-VP O',\n",
              "  'transmitted VBN I-VP O',\n",
              "  'to TO B-PP O',\n",
              "  'sheep NN B-NP O',\n",
              "  '. . O O']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "\n",
        "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "dataset_in_sentence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65c3dfa8",
        "outputId": "a51daf00-e607-4e6d-cc35-e99b3c6dc896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10625"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# [len(sentence) for sentence in dataset_in_sentence]\n",
        "filtered_dataset = [sentence for sentence in dataset_in_sentence if len(sentence) > 5]\n",
        "len(filtered_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset[1000]"
      ],
      "metadata": {
        "id": "byACWZiOjr3l",
        "outputId": "e24c5b72-738c-4869-9405-42628122f89e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\" \" O O',\n",
              " 'I PRP B-NP O',\n",
              " 'think VBP B-VP O',\n",
              " 'this DT B-NP O',\n",
              " 'is VBZ B-VP O',\n",
              " 'a DT B-NP O',\n",
              " 'bad JJ I-NP O',\n",
              " 'beginning NN I-NP O',\n",
              " '. . O O']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1a1714b",
        "outputId": "0b47d97e-c8c2-4c07-a4cc-479651d8b01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word is EU NNP B-NP B-ORG\n",
            "splitted_word is ['EU', 'NNP', 'B-NP', 'B-ORG']\n",
            "EU B-ORG\n",
            "is organization: True\n",
            "['<pad>', '<pad>', 'EU', 'rejects', 'German']\n",
            "word is rejects VBZ B-VP O\n",
            "splitted_word is ['rejects', 'VBZ', 'B-VP', 'O']\n",
            "rejects O\n",
            "is organization: False\n",
            "['<pad>', 'EU', 'rejects', 'German', 'call']\n",
            "word is German JJ B-NP B-MISC\n",
            "splitted_word is ['German', 'JJ', 'B-NP', 'B-MISC']\n",
            "German B-MISC\n",
            "is organization: False\n",
            "['EU', 'rejects', 'German', 'call', 'to']\n",
            "word is call NN I-NP O\n",
            "splitted_word is ['call', 'NN', 'I-NP', 'O']\n",
            "call O\n",
            "is organization: False\n",
            "['rejects', 'German', 'call', 'to', 'boycott']\n",
            "word is to TO B-VP O\n",
            "splitted_word is ['to', 'TO', 'B-VP', 'O']\n",
            "to O\n",
            "is organization: False\n",
            "['German', 'call', 'to', 'boycott', 'British']\n",
            "word is boycott VB I-VP O\n",
            "splitted_word is ['boycott', 'VB', 'I-VP', 'O']\n",
            "boycott O\n",
            "is organization: False\n",
            "['call', 'to', 'boycott', 'British', 'lamb']\n",
            "word is British JJ B-NP B-MISC\n",
            "splitted_word is ['British', 'JJ', 'B-NP', 'B-MISC']\n",
            "British B-MISC\n",
            "is organization: False\n",
            "['to', 'boycott', 'British', 'lamb', '.']\n",
            "word is lamb NN I-NP O\n",
            "splitted_word is ['lamb', 'NN', 'I-NP', 'O']\n",
            "lamb O\n",
            "is organization: False\n",
            "['boycott', 'British', 'lamb', '.', '<pad>']\n",
            "word is . . O O\n",
            "splitted_word is ['.', '.', 'O', 'O']\n",
            ". O\n",
            "is organization: False\n",
            "['British', 'lamb', '.', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "window_len = 2\n",
        "sentence = filtered_dataset[0]\n",
        "\n",
        "for i, word in enumerate(sentence):\n",
        "  print(f'word is {word}')\n",
        "  splitted_word = word.split(' ')\n",
        "  print(f'splitted_word is {splitted_word}')\n",
        "  center_word = splitted_word[0]\n",
        "  label = splitted_word[-1]\n",
        "  print(center_word, label)\n",
        "  is_organization = label in ['B-ORG', 'I-ORG']\n",
        "  print(f\"is organization: {is_organization}\")\n",
        "\n",
        "  # concatenating with neighboring words\n",
        "\n",
        "  # words in the left\n",
        "  prev_index = max(i - window_len, 0) # clipping minimum to zero\n",
        "  prev_words = sentence[prev_index:i]\n",
        "  prev_words = [word_str.split(' ')[0] for word_str in prev_words] # collect the main word\n",
        "\n",
        "  # print(prev_words)\n",
        "\n",
        "  next_index = i + window_len + 1\n",
        "  next_words = sentence[i+1:next_index]\n",
        "  # next_words = [sentence[next_index] ]\n",
        "  next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "  # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "  if len(prev_words) != window_len:\n",
        "    prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "  if len(next_words) != window_len:\n",
        "    next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "  concatenated_words = prev_words + [center_word] + next_words\n",
        "  print(concatenated_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_window_words_and_label_from_sentence(sentence):\n",
        "  total_output = []\n",
        "  for i, word in enumerate(sentence):\n",
        "    splitted_word = word.split(' ')\n",
        "    center_word = splitted_word[0]\n",
        "    label = splitted_word[-1]\n",
        "    is_organization = label in ['B-ORG', 'I-ORG']\n",
        "\n",
        "    # concatenating with neighboring words\n",
        "\n",
        "    # words in the left\n",
        "    prev_index = max(i - window_len, 0) # clipping minimum to zero\n",
        "    prev_words = sentence[prev_index:i]\n",
        "    prev_words = [word_str.split(' ')[0] for word_str in prev_words] # collect the main word\n",
        "\n",
        "    # print(prev_words)\n",
        "\n",
        "    next_index = i + window_len + 1\n",
        "    next_words = sentence[i+1:next_index]\n",
        "    # next_words = [sentence[next_index] ]\n",
        "    next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "    # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "    if len(prev_words) != window_len:\n",
        "      prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "    if len(next_words) != window_len:\n",
        "      next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "    concatenated_words = prev_words + [center_word] + next_words\n",
        "    total_output.append( (concatenated_words, is_organization)  )\n",
        "  return total_output\n",
        "\n",
        "make_window_words_and_label_from_sentence(sentence)\n"
      ],
      "metadata": {
        "id": "z1WVzcMGlZoh",
        "outputId": "094a4895-aa3c-460d-b529-a0b936ee198e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['<pad>', '<pad>', 'EU', 'rejects', 'German'], True),\n",
              " (['<pad>', 'EU', 'rejects', 'German', 'call'], False),\n",
              " (['EU', 'rejects', 'German', 'call', 'to'], False),\n",
              " (['rejects', 'German', 'call', 'to', 'boycott'], False),\n",
              " (['German', 'call', 'to', 'boycott', 'British'], False),\n",
              " (['call', 'to', 'boycott', 'British', 'lamb'], False),\n",
              " (['to', 'boycott', 'British', 'lamb', '.'], False),\n",
              " (['boycott', 'British', 'lamb', '.', '<pad>'], False),\n",
              " (['British', 'lamb', '.', '<pad>', '<pad>'], False)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entire_dataset = [make_window_words_and_label_from_sentence(sentence) for sentence in filtered_dataset ]\n",
        "entire_dataset = [windowed_word for sentence in entire_dataset for windowed_word in sentence]"
      ],
      "metadata": {
        "id": "Ddb7t7PEmHfS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(entire_dataset)"
      ],
      "metadata": {
        "id": "gmQSEfE0mcOc",
        "outputId": "2ce0a2b2-1607-4617-c182-31e0cfcc0272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192587"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entire_dataset[10000]"
      ],
      "metadata": {
        "id": "baTBawNXmg-s",
        "outputId": "76306d4d-e491-4068-9ec7-1023b0657baf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['eight', 'in', 'a', 'row', ','], False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPO83i3UKV8C",
        "outputId": "31e84746-9d12-4a82-f462-0190e695418b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "\n",
        "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtVJXmXnLoN8",
        "outputId": "e9f43726-241b-4d02-c6b9-c25ba1015a49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(wrd2vec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_example = entire_dataset[0]\n",
        "word_list, label = data_example\n",
        "\n",
        "# convert list of word in string into a concatenated vector\n",
        "word_list\n",
        "\n",
        "def get_flattened_vector(word_list:list, wrd2vec):\n",
        "  flattened_vec = []\n",
        "  for word in word_list:\n",
        "    word = word.lower()\n",
        "    if word in wrd2vec:\n",
        "      vec = wrd2vec[word]\n",
        "    else:\n",
        "      vec = np.zeros(300)\n",
        "    # print(vec.shape)\n",
        "    flattened_vec.append(vec)\n",
        "  flattened_vec = np.concatenate(flattened_vec)\n",
        "  return flattened_vec\n",
        "\n",
        "get_flattened_vector(word_list, wrd2vec).shape"
      ],
      "metadata": {
        "id": "a0VrL0q2mvKB",
        "outputId": "83d77576-9a85-4be8-827a-c6684a38608e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vU3qUzW3ps5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__() # initialize nn.Module first\n",
        "    self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.layer2 = nn.Linear(hidden_size, output_size, bias=False)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = self.relu(self.layer1(x))\n",
        "    s = self.layer2(h)\n",
        "    out = self.sigmoid(s)\n",
        "    return out.squeeze()\n",
        "\n",
        "input_vec = get_flattened_vector(word_list, wrd2vec)\n",
        "model = Classifier(input_size=1500, hidden_size=47, output_size=1)\n",
        "model(torch.Tensor(input_vec))"
      ],
      "metadata": {
        "id": "dQDJ1i5eotZU",
        "outputId": "5cbff1e5-c75f-4163-a2f1-8cff577f3a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5294, grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4PtExeIoVkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "nbformat": 4,
    "nbformat_minor": 5
  },
  "nbformat": 4,
  "nbformat_minor": 0
}