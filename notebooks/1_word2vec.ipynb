{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020/blob/main/notebooks/1_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L9BA5Lg2QRMr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEaaz_s0QRMs",
        "outputId": "373d8f38-28c2-48a0-cbeb-68cf0e774ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-14 06:00:46--  https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439742 (429K) [text/plain]\n",
            "Saving to: ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt’\n",
            "\n",
            "\r          J. K. Row   0%[                    ]       0  --.-KB/s               \rJ. K. Rowling - Har 100%[===================>] 429.44K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-03-14 06:00:47 (11.4 MB/s) - ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt’ saved [439742/439742]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CUsXJYlIQRMs"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(x):\n",
        "  return x.translate(''.maketrans('', '', string.punctuation))\n",
        "\n",
        "def make_tokenized_corpus(corpus):\n",
        "  out= [ [y.lower() for y in remove_punctuation(sentence).split(' ') if y] for sentence in corpus]\n",
        "  return [x for x in out if x!=[]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ry1o-F-bQRMs"
      },
      "outputs": [],
      "source": [
        "with open(\"J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\", 'r') as f:\n",
        "  strings = f.readlines()\n",
        "sample_text = \"\".join(strings).replace('\\n', ' ').replace('Mr.', 'mr').replace('Mrs.', 'mrs').split('. ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne-pUaxSQRMs",
        "outputId": "1567210e-bc9b-4ace-c787-0ace0cc49739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['they', 'were', 'the', 'last', 'people', 'youd', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense']\n"
          ]
        }
      ],
      "source": [
        "corpus = make_tokenized_corpus(sample_text)\n",
        "print(corpus[1]) # Corpus is a list of list of strings (words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv-VvzzXkAnZ",
        "outputId": "5c8c898a-9375-40d1-c9f0-91957d7fb8ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['they',\n",
              " 'were',\n",
              " 'the',\n",
              " 'last',\n",
              " 'people',\n",
              " 'youd',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'be',\n",
              " 'involved',\n",
              " 'in',\n",
              " 'anything',\n",
              " 'strange',\n",
              " 'or',\n",
              " 'mysterious',\n",
              " 'because',\n",
              " 'they',\n",
              " 'just',\n",
              " 'didnt',\n",
              " 'hold',\n",
              " 'with',\n",
              " 'such',\n",
              " 'nonsense']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from copy import copy\n",
        "copy(corpus[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UxJwTAacWfP",
        "outputId": "a32ec395-d794-4b81-9944-4de65a5b9a4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4682/4682 [00:00<00:00, 6817.90it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "282372"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "sample_sentence = ['they', 'were', 'the', 'last', 'people', 'youd', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense']\n",
        "\n",
        "word_idx = 7\n",
        "window_size = 2\n",
        "selected_center_word = sample_sentence[word_idx]\n",
        "\n",
        "word_pairs = []\n",
        "\n",
        "for sample_sentence in tqdm(corpus): # tqdm shows the progress bar of for loop\n",
        "  for word_idx, word in enumerate(sample_sentence):\n",
        "    for context_idx in range(-window_size, window_size+1):\n",
        "      if context_idx == 0: continue\n",
        "      context_word_idx = word_idx + context_idx\n",
        "      if context_word_idx >= len(sample_sentence) or context_word_idx < 0: continue\n",
        "      # print(context_idx, context_word_idx, sample_sentence[word_idx], sample_sentence[context_word_idx])\n",
        "      word_pair = [word, sample_sentence[context_word_idx]]\n",
        "      word_pairs.append(word_pair)\n",
        "len(word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxcnHM7egR2o",
        "outputId": "1f61c69f-f86a-4a60-fbb1-bbefbc155e68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mixing', 'dudley']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_pairs[1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htinJiMPkkRE"
      },
      "outputs": [],
      "source": [
        "# we have to make vocabulary\n",
        "\n",
        "total_words = []\n",
        "for sentence in corpus:\n",
        "  # print(sentence)\n",
        "  for word in sentence:\n",
        "    total_words.append(word)\n",
        "\n",
        "print(total_words[:100])\n",
        "# for a in corpus:\n",
        "#   for b in a:\n",
        "#     c.append(b)\n",
        "# always use proper variable name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERBFCjeslgDe"
      },
      "outputs": [],
      "source": [
        "# we have to get the \"unique\" item among total words\n",
        "vocab_set = set(total_words)\n",
        "print(len(total_words), len(vocab_set))\n",
        "print(vocab_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDJNrHdhl_dk"
      },
      "outputs": [],
      "source": [
        "# this will make error\n",
        "# vocab_set[0] # set is not subscriptable because it has no order\n",
        "\n",
        "vocab = list(vocab_set) # converting set into list, so that we can order the items\n",
        "# sort the liset\n",
        "vocab = sorted(vocab)\n",
        "# vocab.sort()\n",
        "print(vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOkBSjrkmNE4",
        "outputId": "a683ccb6-87b6-4035-bb0e-3ea0d52452be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1701\n"
          ]
        }
      ],
      "source": [
        "# how can we filter the vocab by its frequency?\n",
        "from collections import Counter\n",
        "word_counter = Counter(total_words)\n",
        "# word_counter['hundreds']\n",
        "len(word_counter)\n",
        "\n",
        "# you can use word counter as dictionary\n",
        "# In python dictionary, dict.keys() gives keys, and dict.values() give values,\n",
        "# dict.items() give (key, value)\n",
        "filtered_vocab = []\n",
        "minimum_occur = 5\n",
        "for key, value in word_counter.items():\n",
        "  if value >= minimum_occur:\n",
        "    filtered_vocab.append(key)\n",
        "print(len(filtered_vocab))\n",
        "filtered_vocab.sort() # you must not declare filtered_vocab = filtered_vocab.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQ3xsHFoheU"
      },
      "outputs": [],
      "source": [
        "print(filtered_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XUS6U7y7opUp",
        "outputId": "a9af4af5-ce0a-4089-c2d8-57f75629da4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 59387/282372 [00:01<00:07, 31526.39it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-5452bc3a57bd>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# word_b = pair[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# we will include this pair only if both words are in the vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mword_a\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_vocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mfiltered_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Filter the word_pairs using the vocab\n",
        "# word_pairs, filtered_vocab\n",
        "# word_pairs is a list of [word_a, word_b]\n",
        "\n",
        "filtered_pairs = []\n",
        "for pair in tqdm(word_pairs):\n",
        "  word_a, word_b = pair\n",
        "  # word_a = pair[0]\n",
        "  # word_b = pair[1]\n",
        "  # we will include this pair only if both words are in the vocab\n",
        "  if word_a in filtered_vocab and word_b in filtered_vocab:\n",
        "    filtered_pairs.append(pair)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "U-o4UucOrcem"
      },
      "outputs": [],
      "source": [
        "# implement same algorithm with list comprehension\n",
        "filtered_pairs = [pair for pair in word_pairs\n",
        "                  if pair[0] in filtered_vocab and pair[1] in filtered_vocab]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz_8ch59ps_P",
        "outputId": "99e13b9d-5cbd-4272-ebd4-d5082ae9662c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(233046, 282372)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(filtered_pairs), len(word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmTMaftiqnsA",
        "outputId": "ad033665-eec4-4031-9224-f4deef890a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['happily', 'she']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_pairs[1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFJfhOznqyi-",
        "outputId": "8cb64a90-31bb-4ab6-afa7-54e369b4512e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 233046/233046 [00:08<00:00, 28719.18it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "233046"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert word into index of vocab\n",
        "filtered_vocab.index('happily')\n",
        "\n",
        "index_pairs = []\n",
        "for word_a, word_b in tqdm(filtered_pairs):\n",
        "  word_a_idx = filtered_vocab.index(word_a)\n",
        "  word_b_idx = filtered_vocab.index(word_b)\n",
        "  index_pairs.append([word_a_idx, word_b_idx])\n",
        "len(index_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xDCmtRjgtXAc",
        "outputId": "567b972b-40d6-4309-c87d-eaeceae41c39"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'behind'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_vocab[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D8n16VitIHP",
        "outputId": "f1dccd55-dd74-4998-ed5b-8b0a5506620e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "613"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can make it faster\n",
        "# use dictionary to find the index of string\n",
        "\n",
        "# adict['behind'] = 100\n",
        "# tok2idx = {}\n",
        "# for idx, word in enumerate(filtered_vocab):\n",
        "#   tok2idx[word] = idx # word becomes key, idx becomes value\n",
        "\n",
        "tok2idx = {word: idx for idx, word in enumerate(filtered_vocab)}\n",
        "\n",
        "tok2idx['harry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utXemuOgt8-o",
        "outputId": "4a0de8ca-da9d-42a8-bc64-e1ecf48bbbed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 233046/233046 [00:00<00:00, 537845.43it/s]\n"
          ]
        }
      ],
      "source": [
        "index_pairs = []\n",
        "for word_a, word_b in tqdm(filtered_pairs):\n",
        "  word_a_idx = tok2idx[word_a]\n",
        "  word_b_idx = tok2idx[word_b]\n",
        "  index_pairs.append([word_a_idx, word_b_idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgQ_oSNGuZAd",
        "outputId": "f30bacc9-18be-4313-c2ad-36ffe88f070c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('harry', 'potter')"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Why we don't need idx2tok?\n",
        "\n",
        "def convert_idx_pairs_to_string(pair):\n",
        "  # pair: [int, int]\n",
        "  idxa, idxb= pair\n",
        "  return filtered_vocab[idxa], filtered_vocab[idxb]\n",
        "convert_idx_pairs_to_string(index_pairs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygV93qzDu4Ls",
        "outputId": "feff8b48-6e06-4168-c9f7-6808d263ddb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.2139,  0.2560, -0.1631,  ..., -0.5057, -0.0050, -0.1986],\n",
              "         [-0.0261, -0.0950,  0.0102,  ..., -0.2876,  0.0060, -0.4206],\n",
              "         [ 0.0215, -0.1089, -0.2158,  ..., -0.3356, -0.1273, -0.1058],\n",
              "         ...,\n",
              "         [-0.1933,  0.1937, -0.3518,  ...,  0.2688, -0.0190, -0.2909],\n",
              "         [ 0.0930, -0.0169, -0.2924,  ..., -0.1347, -0.0863,  0.1162],\n",
              "         [ 0.0539,  0.1383, -0.1870,  ...,  0.2358,  0.1057, -0.5139]]),\n",
              " torch.Size([1701, 8]))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we have to make random vectors for each word in the vocab\n",
        "# we also have to decide the dimension of the vector\n",
        "\n",
        "dim = 8\n",
        "vocab_size = len(filtered_vocab)\n",
        "\n",
        "word_vectors = torch.randn(vocab_size, dim) / 4\n",
        "word_vectors, word_vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmZcT53rvwW2",
        "outputId": "a953448c-4069-455b-fa1c-9c12eafba1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "613\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 0.2799, -0.0560, -0.1426, -0.2151,  0.1446,  0.0032,  0.2464,  0.1845])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what is the vector for harry?\n",
        "idx_of_harry = tok2idx['harry']\n",
        "print(idx_of_harry)\n",
        "vector_of_harry = word_vectors[idx_of_harry]\n",
        "vector_of_harry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1qznszMwyTg",
        "outputId": "780fb829-9616-45dd-a4cb-132a10864b19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['harry', 'potter'], [613, 1085])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_pairs[0], index_pairs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4bEKFvUxbVv",
        "outputId": "93042a05-9aad-4b77-a15e-a719afab8830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.2799, -0.0560, -0.1426, -0.2151,  0.1446,  0.0032,  0.2464,  0.1845])\n",
            "tensor([-0.0734,  0.3600,  0.0707,  0.1023,  0.1533, -0.0307,  0.0791, -0.1671])\n",
            "tensor([    -0.0205,     -0.0202,     -0.0101,     -0.0220,      0.0222,\n",
            "            -0.0001,      0.0195,     -0.0308])\n",
            "tensor(-0.0621)\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "print(vector_of_harry)\n",
        "print(vector_of_potter)\n",
        "print(vector_of_harry * vector_of_potter)\n",
        "print(sum(vector_of_harry * vector_of_potter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dot Product\n",
        "- Assume we have two vectors $a$ and $b$.\n",
        "  - $a = [a_1, a_2, a_3, a_4, ..., a_n]$\n",
        "  - $b = [b_1, b_2, b_3, b_4, ..., b_n]$\n",
        "- $a \\cdot b$ = $\\sum _{i=1}^n a_ib_i$  = $a_1b_1 + a_2b_2 + a_3b_3 + a_4b_4 + ... + a_nb_n$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsse-jUrw6c2",
        "outputId": "b0197a51-f139-4aa6-eafc-d99cba59d67e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.0621)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate P(potter|harry)\n",
        "\n",
        "vector_of_potter = word_vectors[tok2idx['potter']]\n",
        "vector_of_harry, vector_of_potter\n",
        "\n",
        "dot_product_value_between_potter_harry = torch.dot(vector_of_harry, vector_of_potter)\n",
        "dot_product_value_between_potter_harry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZrLEY36yBNZ"
      },
      "outputs": [],
      "source": [
        "# we can get the dot product value for every other words in the vocab\n",
        "# to get  P(word | harry)\n",
        "word_dot_dict = {}\n",
        "for word in filtered_vocab:\n",
        "  word_vector = word_vectors[tok2idx[word]]\n",
        "  dot_product_value = torch.dot(vector_of_harry, word_vector)\n",
        "  word_dot_dict[word] = dot_product_value.item()\n",
        "\n",
        "word_dot_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ1PUvuLyv6r"
      },
      "outputs": [],
      "source": [
        "# we have to convert our prediction into probability distribution\n",
        "# P(word|harry)\n",
        "# sum of [P(a|harry), ..., P(potter|harry), ... P(ron|harry), ... ] = 1\n",
        "\n",
        "# every probability should be in range (0, 1) (greater than 0, smaller than 1)\n",
        "# this can be handled by taking exponential of dot product values, divided by total sum\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matrix Multiplication as Dot Product\n",
        "![img](https://mkang32.github.io/images/python/khan_academy_matrix_product.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK--Pbqge6Tf",
        "outputId": "f7064335-9c2d-4182-cff6-573cb695e4be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21, 23, 23)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_idx, context_word_idx, len(sample_sentence)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
